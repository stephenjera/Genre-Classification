{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import librosa\n",
    "import dagshub\n",
    "import mlflow\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # GPU is available\n",
    "    print(\"GPU is available.\")\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    # GPU is not available\n",
    "    print(\"GPU is not available. PyTorch will use the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dagshub.init(repo_owner=\"stephenjera\", repo_name=\"Genre-Classification\", mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "DURATION = 30  # length of audio files measured in seconds\n",
    "NUM_SEGMENTS = 1\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = Path.cwd().parent / \"data\"\n",
    "genres_dir = data_directory / \"genres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mfcc(\n",
    "    dataset_path: str | Path, #Can input the path or of string format\n",
    "    json_path: str,\n",
    "    samples_per_track: int,\n",
    "    n_mfcc=13,\n",
    "    n_fft=2048,\n",
    "    hop_length=512,\n",
    "    num_segments=5,\n",
    "):\n",
    "    \"\"\"Creates a JSON file of the MFCCs for the dataset\n",
    "    :param\n",
    "    ----------\n",
    "     dataset_path: path to the dataset folder\n",
    "     json_path: name of JSON file to be created\n",
    "     n_mfcc: number of MFCC coefficients to create\n",
    "     n_fft:\n",
    "     hop_length:\n",
    "     num_segments:\n",
    "\n",
    "    \"\"\"\n",
    "    # Create a dictionary to map semantic labels to numerical labels\n",
    "    semantic_to_numeric = {}\n",
    "    # dictionary to store data\n",
    "    data = {\n",
    "        \"mappings\": {},\n",
    "        \"mfcc\": [],\n",
    "        \"labels\": [],\n",
    "    }\n",
    "    num_samples_per_segment = int(samples_per_track / num_segments)\n",
    "    expected_num_mfcc_vectors_per_segment = ceil(\n",
    "        num_samples_per_segment / hop_length\n",
    "    )  # round up always\n",
    "\n",
    "    # Loop through all the data\n",
    "    for i, (dirpath, _, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        # dirpath = current folder path\n",
    "        # dirnames = subfolders in dirpath\n",
    "        # filenames = all files in dirpath\n",
    "\n",
    "        # ensure that we're not at the root level (Audio folder)\n",
    "        if dirpath != str(dataset_path):\n",
    "            # save the semantic label\n",
    "            dirpath_components = dirpath.split(os.sep)\n",
    "            semantic_label = dirpath_components[-1]\n",
    "            # Subtract 1 to skip the root folder\n",
    "            semantic_to_numeric[semantic_label] = i - 1\n",
    "            print(f\"\\nProcessing {semantic_label}\")\n",
    "\n",
    "            # process files\n",
    "            for filename in filenames:\n",
    "                # load audio file\n",
    "                file_path = Path(dirpath, filename)  # os.path.join(dirpath, filename)\n",
    "                try:\n",
    "                    signal, sr = librosa.load(\n",
    "                        file_path  # , sr=SAMPLE_RATE, duration=DURATION\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_path}: {e}\")\n",
    "                    continue\n",
    "                # process segments extracting mfcc and storing data\n",
    "                for s in range(num_segments):\n",
    "                    start_sample = num_samples_per_segment * s\n",
    "                    finish_sample = start_sample + num_samples_per_segment\n",
    "\n",
    "                    mfcc = librosa.feature.mfcc(\n",
    "                        y=signal[start_sample:finish_sample],\n",
    "                        sr=sr,\n",
    "                        n_fft=n_fft,\n",
    "                        n_mfcc=n_mfcc,\n",
    "                        hop_length=hop_length,\n",
    "                    )\n",
    "                    mfcc = mfcc.T\n",
    "\n",
    "                    # store mfcc for segment if it has expected length\n",
    "                    if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n",
    "                        # can't save numpy arrays as json files\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i - 1)\n",
    "                        print(f\"{file_path}, segment:{s+1}\")\n",
    "    data[\"mappings\"] = semantic_to_numeric\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mfcc(genres_dir, \"data.json\", SAMPLES_PER_TRACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "    \"\"\"\n",
    "    Loads training dataset from json file.\n",
    "        :param data_path (str): Path to json file containing data\n",
    "        :return X (ndarray): Inputs\n",
    "        :return y (ndarray): Targets\n",
    "    \"\"\"\n",
    "\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    # convert lists to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    # X = np.array(data[\"spectrogram\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "    mappings = data[\"mappings\"]\n",
    "    return X, y, mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model\n",
    "class LSTMGenreModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super().__init__() # super initialises attributes of parent class\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x): #Forward tells PyTorch how to manipulate the data\n",
    "        # x shape: (batch, seq_len, input_size)\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        # out shape: (batch, seq_len, hidden_size)\n",
    "\n",
    "        # Take the final output and classify\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        # out shape: (batch, num_classes)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Dataset\n",
    "class MFCCDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfccs = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        return mfccs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, mappings = load_data(\"data.json\")\n",
    "X = torch.tensor(np.array(X, dtype=np.float32)).clone().detach()\n",
    "y = torch.tensor(y, dtype=torch.long).clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(X, y, test_size, validation_size, shuffle=True, random_state=42):\n",
    "    # create train, validation and test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, shuffle=shuffle, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # create train/validation split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=validation_size\n",
    "    )\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 10  # number of genres\n",
    "input_size = 13  # number of MFCC coefficients\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_val, labels_val = prepare_datasets(X, y, 0.25, 0.2)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = MFCCDataset(X_train, y_train)\n",
    "test_dataset = MFCCDataset(X_test, y_test)\n",
    "val_dataset = MFCCDataset(X_val, labels_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train model\n",
    "model = LSTMGenreModel(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "sample_input = torch.zeros(1, 128, 13).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss() # Used for our loss function\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    for mfccs_test, labels_test in train_loader:\n",
    "        # Move tensors to CUDA\n",
    "        mfccs_test = mfccs_test.to(device)\n",
    "        labels_test = labels_test.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # Zero out the gradients else would be a combination of old gradient\n",
    "        # Forward pass\n",
    "        outputs = model(mfccs_test)\n",
    "\n",
    "        loss = criterion(outputs, labels_test)\n",
    "        loss.backward() # Applies back propogation\n",
    "        optimizer.step() # updating the weights\n",
    "\n",
    "        # Track training metrics\n",
    "        train_loss += loss.item()\n",
    "        # Calculate accuracy for current batch\n",
    "        batch_correct = (outputs.argmax(1) == labels_test).float().sum()\n",
    "        # Convert to python scalar for logging\n",
    "        train_correct += batch_correct.item()\n",
    "    # Average training metrics\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = train_correct / len(train_loader.dataset)  # type: ignore\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "\n",
    "    with torch.no_grad(): # no grad is a context manager, model does not calculate gradient \n",
    "        for mfccs_val, labels_val in val_loader:\n",
    "            # Move tensors to CUDA\n",
    "            mfccs_val = mfccs_val.to(device)\n",
    "            labels_val = labels_val.to(device)\n",
    "            outputs = model(mfccs_val)\n",
    "            val_loss += criterion(outputs, labels_val).item()\n",
    "            val_correct += (outputs.argmax(1) == labels_val).sum().item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_accuracy = val_correct / len(test_loader.dataset)  # type: ignore\n",
    "\n",
    "    # Log metrics to TensorBoard\n",
    "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/Valid\", val_loss, epoch)\n",
    "\n",
    "    writer.add_scalar(\"Accuracy/Train\", train_accuracy, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Valid\", val_accuracy, epoch)\n",
    "\n",
    "    # Log FC layer weights\n",
    "    writer.add_histogram(\"FC Weights\", model.fc.weight)\n",
    "\n",
    "    # Log RNN layer weights\n",
    "    writer.add_histogram(\"RNN Weights\", model.lstm.weight_ih_l0)\n",
    "\n",
    "    writer.add_graph(model, sample_input)\n",
    "\n",
    "model.to(\"cpu\")\n",
    "\n",
    "# Evaluation\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for mfccs_test, labels_test in test_loader:\n",
    "        outputs = model(mfccs_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels_test.size(0)\n",
    "        correct += (predicted == labels_test).sum().item()\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log parameters\n",
    "mlflow.start_run()\n",
    "\n",
    "mlflow.log_metric(\"accuracy\", accuracy)\n",
    "mlflow.log_param(\"SAMPLE_RATE\", SAMPLE_RATE)\n",
    "mlflow.log_param(\"DURATION\", DURATION)\n",
    "mlflow.log_param(\"NUM_SEGMENTS\", NUM_SEGMENTS)\n",
    "mlflow.log_param(\"SAMPLES_PER_TRACK\", SAMPLES_PER_TRACK)\n",
    "mlflow.log_param(\"num_classes\", num_classes)\n",
    "mlflow.log_param(\"input_size\", input_size)\n",
    "mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "mlflow.log_param(\"num_layers\", num_layers)\n",
    "mlflow.log_param(\"batch_size\", batch_size)\n",
    "mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "mlflow.log_param(\n",
    "    \"data_version\",\n",
    "    subprocess.check_output(\n",
    "        [\"git\", \"rev-parse\", \"HEAD\"], universal_newlines=True\n",
    "    ).strip(),\n",
    ")\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "pred_model = LSTMGenreModel(input_size, hidden_size, num_layers, num_classes)\n",
    "pred_model.load_state_dict(torch.load('model.pth'))\n",
    "pred_model.eval()\n",
    "# Assuming that `data` is your new input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_data = torch.tensor(test_loader.dataset.X[0])\n",
    "if len(single_data.shape) < 3:\n",
    "    # Add one dimension for batch with unsqueeze() if your data is 2D (sequence length, features)\n",
    "    single_data = single_data.unsqueeze(0)\n",
    "    #print(single_data.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(single_data)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predicted_genre_name = list(mappings.keys())[list(mappings.values()).index(predicted.item())]\n",
    "    actual_genre_name = list(mappings.keys())[list(mappings.values()).index(test_loader.dataset.y[0])]\n",
    "    print(f\"Predicted class: {predicted_genre_name} {predicted.item()}, Actual: {actual_genre_name} {test_loader.dataset.y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `true_labels` is a list of true labels and `pred_labels` is a list of predicted labels\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mfcc, label in test_loader:\n",
    "        outputs = model(mfcc)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_labels.extend(label.tolist())\n",
    "        pred_labels.extend(predicted.tolist())\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "# Get genre names in the order of label numbers\n",
    "genre_names = [k for k, v in sorted(mappings.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Plot confusion matrix with genre names as labels\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=genre_names,\n",
    "    yticklabels=genre_names,\n",
    "    ax=ax\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "\n",
    "# Rotate y-axis labels\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Log the confusion matrix as an image to TensorBoard\n",
    "writer.add_figure('Confusion Matrix', fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Start TensorBoard within the notebook using magics function\n",
    "%tensorboard --logdir runs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Genre-Classification-Tl9UQQdU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
