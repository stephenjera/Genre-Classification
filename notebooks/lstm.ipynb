{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/harjitgakhal/Documents/Genre-Classification/notebooks/lstm.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harjitgakhal/Documents/Genre-Classification/notebooks/lstm.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlibrosa\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harjitgakhal/Documents/Genre-Classification/notebooks/lstm.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdagshub\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/harjitgakhal/Documents/Genre-Classification/notebooks/lstm.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmlflow\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harjitgakhal/Documents/Genre-Classification/notebooks/lstm.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msubprocess\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harjitgakhal/Documents/Genre-Classification/notebooks/lstm.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Genre-Classification-SloK1xDu/lib/python3.10/site-packages/mlflow/__init__.py:44\u001b[0m\n\u001b[1;32m     41\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumpy.dtype size changed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumpy.ufunc size changed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmlflow\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     45\u001b[0m     artifacts,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     client,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     data,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     exceptions,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     models,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     projects,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     tracking,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     54\u001b[0m \u001b[39m# Lazily load mlflow flavors to avoid excessive dependencies.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m catboost \u001b[39m=\u001b[39m LazyLoader(\u001b[39m\"\u001b[39m\u001b[39mmlflow.catboost\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mglobals\u001b[39m(), \u001b[39m\"\u001b[39m\u001b[39mmlflow.catboost\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Genre-Classification-SloK1xDu/lib/python3.10/site-packages/mlflow/data/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Union\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmlflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m dataset_registry\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmlflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m sources \u001b[39mas\u001b[39;00m mlflow_data_sources\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmlflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Genre-Classification-SloK1xDu/lib/python3.10/site-packages/mlflow/data/dataset_registry.py:132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m# use contextlib suppress to ignore import errors\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m suppress(\u001b[39mImportError\u001b[39;00m):\n\u001b[0;32m--> 132\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmlflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpandas_dataset\u001b[39;00m \u001b[39mimport\u001b[39;00m from_pandas\n\u001b[1;32m    134\u001b[0m     _dataset_registry\u001b[39m.\u001b[39mregister_constructor(from_pandas)\n\u001b[1;32m    135\u001b[0m \u001b[39mwith\u001b[39;00m suppress(\u001b[39mImportError\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Genre-Classification-SloK1xDu/lib/python3.10/site-packages/mlflow/data/pandas_dataset.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunctools\u001b[39;00m \u001b[39mimport\u001b[39;00m cached_property\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Dict, Optional, Union\n\u001b[0;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmlflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmlflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_source\u001b[39;00m \u001b[39mimport\u001b[39;00m DatasetSource\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Genre-Classification-SloK1xDu/lib/python3.10/site-packages/pandas/__init__.py:46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39m# let init-time option registration happen\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig_init\u001b[39;00m  \u001b[39m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     \u001b[39m# dtype\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     ArrowDtype,\n\u001b[1;32m     49\u001b[0m     Int8Dtype,\n\u001b[1;32m     50\u001b[0m     Int16Dtype,\n\u001b[1;32m     51\u001b[0m     Int32Dtype,\n\u001b[1;32m     52\u001b[0m     Int64Dtype,\n\u001b[1;32m     53\u001b[0m     UInt8Dtype,\n\u001b[1;32m     54\u001b[0m     UInt16Dtype,\n\u001b[1;32m     55\u001b[0m     UInt32Dtype,\n\u001b[1;32m     56\u001b[0m     UInt64Dtype,\n\u001b[1;32m     57\u001b[0m     Float32Dtype,\n\u001b[1;32m     58\u001b[0m     Float64Dtype,\n\u001b[1;32m     59\u001b[0m     CategoricalDtype,\n\u001b[1;32m     60\u001b[0m     PeriodDtype,\n\u001b[1;32m     61\u001b[0m     IntervalDtype,\n\u001b[1;32m     62\u001b[0m     DatetimeTZDtype,\n\u001b[1;32m     63\u001b[0m     StringDtype,\n\u001b[1;32m     64\u001b[0m     BooleanDtype,\n\u001b[1;32m     65\u001b[0m     \u001b[39m# missing\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     NA,\n\u001b[1;32m     67\u001b[0m     isna,\n\u001b[1;32m     68\u001b[0m     isnull,\n\u001b[1;32m     69\u001b[0m     notna,\n\u001b[1;32m     70\u001b[0m     notnull,\n\u001b[1;32m     71\u001b[0m     \u001b[39m# indexes\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     Index,\n\u001b[1;32m     73\u001b[0m     CategoricalIndex,\n\u001b[1;32m     74\u001b[0m     RangeIndex,\n\u001b[1;32m     75\u001b[0m     MultiIndex,\n\u001b[1;32m     76\u001b[0m     IntervalIndex,\n\u001b[1;32m     77\u001b[0m     TimedeltaIndex,\n\u001b[1;32m     78\u001b[0m     DatetimeIndex,\n\u001b[1;32m     79\u001b[0m     PeriodIndex,\n\u001b[1;32m     80\u001b[0m     IndexSlice,\n\u001b[1;32m     81\u001b[0m     \u001b[39m# tseries\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     NaT,\n\u001b[1;32m     83\u001b[0m     Period,\n\u001b[1;32m     84\u001b[0m     period_range,\n\u001b[1;32m     85\u001b[0m     Timedelta,\n\u001b[1;32m     86\u001b[0m     timedelta_range,\n\u001b[1;32m     87\u001b[0m     Timestamp,\n\u001b[1;32m     88\u001b[0m     date_range,\n\u001b[1;32m     89\u001b[0m     bdate_range,\n\u001b[1;32m     90\u001b[0m     Interval,\n\u001b[1;32m     91\u001b[0m     interval_range,\n\u001b[1;32m     92\u001b[0m     DateOffset,\n\u001b[1;32m     93\u001b[0m     \u001b[39m# conversion\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     to_numeric,\n\u001b[1;32m     95\u001b[0m     to_datetime,\n\u001b[1;32m     96\u001b[0m     to_timedelta,\n\u001b[1;32m     97\u001b[0m     \u001b[39m# misc\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     Flags,\n\u001b[1;32m     99\u001b[0m     Grouper,\n\u001b[1;32m    100\u001b[0m     factorize,\n\u001b[1;32m    101\u001b[0m     unique,\n\u001b[1;32m    102\u001b[0m     value_counts,\n\u001b[1;32m    103\u001b[0m     NamedAgg,\n\u001b[1;32m    104\u001b[0m     array,\n\u001b[1;32m    105\u001b[0m     Categorical,\n\u001b[1;32m    106\u001b[0m     set_eng_float_format,\n\u001b[1;32m    107\u001b[0m     Series,\n\u001b[1;32m    108\u001b[0m     DataFrame,\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    111\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseDtype\n\u001b[1;32m    113\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtseries\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m infer_freq\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Genre-Classification-SloK1xDu/lib/python3.10/site-packages/pandas/core/api.py:28\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmissing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     isna,\n\u001b[1;32m     18\u001b[0m     isnull,\n\u001b[1;32m     19\u001b[0m     notna,\n\u001b[1;32m     20\u001b[0m     notnull,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malgorithms\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     factorize,\n\u001b[1;32m     25\u001b[0m     unique,\n\u001b[1;32m     26\u001b[0m     value_counts,\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m \u001b[39mimport\u001b[39;00m Categorical\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mboolean\u001b[39;00m \u001b[39mimport\u001b[39;00m BooleanDtype\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfloating\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     Float32Dtype,\n\u001b[1;32m     32\u001b[0m     Float64Dtype,\n\u001b[1;32m     33\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Genre-Classification-SloK1xDu/lib/python3.10/site-packages/pandas/core/arrays/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrow\u001b[39;00m \u001b[39mimport\u001b[39;00m ArrowExtensionArray\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     ExtensionArray,\n\u001b[1;32m      4\u001b[0m     ExtensionOpsMixin,\n\u001b[1;32m      5\u001b[0m     ExtensionScalarOpsMixin,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mboolean\u001b[39;00m \u001b[39mimport\u001b[39;00m BooleanArray\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Genre-Classification-SloK1xDu/lib/python3.10/site-packages/pandas/core/arrays/arrow/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marray\u001b[39;00m \u001b[39mimport\u001b[39;00m ArrowExtensionArray\n\u001b[1;32m      3\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mArrowExtensionArray\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Genre-Classification-SloK1xDu/lib/python3.10/site-packages/pandas/core/arrays/arrow/array.py:51\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     missing,\n\u001b[1;32m     48\u001b[0m     roperator,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marraylike\u001b[39;00m \u001b[39mimport\u001b[39;00m OpsMixin\n\u001b[0;32m---> 51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_arrow_string_mixins\u001b[39;00m \u001b[39mimport\u001b[39;00m ArrowStringArrayMixin\n\u001b[1;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     53\u001b[0m     ExtensionArray,\n\u001b[1;32m     54\u001b[0m     ExtensionArraySupportsAnyAll,\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmasked\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseMaskedArray\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Genre-Classification-SloK1xDu/lib/python3.10/site-packages/pandas/core/arrays/_arrow_string_mixins.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m pa_version_under7p0:\n\u001b[1;32m     10\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpyarrow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpa\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpyarrow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompute\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpc\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mArrowStringArrayMixin\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     _pa_array \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Genre-Classification-SloK1xDu/lib/python3.10/site-packages/pyarrow/compute.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Licensed to the Apache Software Foundation (ASF) under one\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# or more contributor license agreements.  See the NOTICE file\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# distributed with this work for additional information\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# specific language governing permissions and limitations\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# under the License.\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyarrow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_compute\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     Function,\n\u001b[1;32m     20\u001b[0m     FunctionOptions,\n\u001b[1;32m     21\u001b[0m     FunctionRegistry,\n\u001b[1;32m     22\u001b[0m     HashAggregateFunction,\n\u001b[1;32m     23\u001b[0m     HashAggregateKernel,\n\u001b[1;32m     24\u001b[0m     Kernel,\n\u001b[1;32m     25\u001b[0m     ScalarAggregateFunction,\n\u001b[1;32m     26\u001b[0m     ScalarAggregateKernel,\n\u001b[1;32m     27\u001b[0m     ScalarFunction,\n\u001b[1;32m     28\u001b[0m     ScalarKernel,\n\u001b[1;32m     29\u001b[0m     VectorFunction,\n\u001b[1;32m     30\u001b[0m     VectorKernel,\n\u001b[1;32m     31\u001b[0m     \u001b[39m# Option classes\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     ArraySortOptions,\n\u001b[1;32m     33\u001b[0m     AssumeTimezoneOptions,\n\u001b[1;32m     34\u001b[0m     CastOptions,\n\u001b[1;32m     35\u001b[0m     CountOptions,\n\u001b[1;32m     36\u001b[0m     CumulativeOptions,\n\u001b[1;32m     37\u001b[0m     CumulativeOptions \u001b[39mas\u001b[39;00m CumulativeSumOptions,\n\u001b[1;32m     38\u001b[0m     DayOfWeekOptions,\n\u001b[1;32m     39\u001b[0m     DictionaryEncodeOptions,\n\u001b[1;32m     40\u001b[0m     RunEndEncodeOptions,\n\u001b[1;32m     41\u001b[0m     ElementWiseAggregateOptions,\n\u001b[1;32m     42\u001b[0m     ExtractRegexOptions,\n\u001b[1;32m     43\u001b[0m     FilterOptions,\n\u001b[1;32m     44\u001b[0m     IndexOptions,\n\u001b[1;32m     45\u001b[0m     JoinOptions,\n\u001b[1;32m     46\u001b[0m     ListSliceOptions,\n\u001b[1;32m     47\u001b[0m     MakeStructOptions,\n\u001b[1;32m     48\u001b[0m     MapLookupOptions,\n\u001b[1;32m     49\u001b[0m     MatchSubstringOptions,\n\u001b[1;32m     50\u001b[0m     ModeOptions,\n\u001b[1;32m     51\u001b[0m     NullOptions,\n\u001b[1;32m     52\u001b[0m     PadOptions,\n\u001b[1;32m     53\u001b[0m     PairwiseOptions,\n\u001b[1;32m     54\u001b[0m     PartitionNthOptions,\n\u001b[1;32m     55\u001b[0m     QuantileOptions,\n\u001b[1;32m     56\u001b[0m     RandomOptions,\n\u001b[1;32m     57\u001b[0m     RankOptions,\n\u001b[1;32m     58\u001b[0m     ReplaceSliceOptions,\n\u001b[1;32m     59\u001b[0m     ReplaceSubstringOptions,\n\u001b[1;32m     60\u001b[0m     RoundBinaryOptions,\n\u001b[1;32m     61\u001b[0m     RoundOptions,\n\u001b[1;32m     62\u001b[0m     RoundTemporalOptions,\n\u001b[1;32m     63\u001b[0m     RoundToMultipleOptions,\n\u001b[1;32m     64\u001b[0m     ScalarAggregateOptions,\n\u001b[1;32m     65\u001b[0m     SelectKOptions,\n\u001b[1;32m     66\u001b[0m     SetLookupOptions,\n\u001b[1;32m     67\u001b[0m     SliceOptions,\n\u001b[1;32m     68\u001b[0m     SortOptions,\n\u001b[1;32m     69\u001b[0m     SplitOptions,\n\u001b[1;32m     70\u001b[0m     SplitPatternOptions,\n\u001b[1;32m     71\u001b[0m     StrftimeOptions,\n\u001b[1;32m     72\u001b[0m     StrptimeOptions,\n\u001b[1;32m     73\u001b[0m     StructFieldOptions,\n\u001b[1;32m     74\u001b[0m     TakeOptions,\n\u001b[1;32m     75\u001b[0m     TDigestOptions,\n\u001b[1;32m     76\u001b[0m     TrimOptions,\n\u001b[1;32m     77\u001b[0m     Utf8NormalizeOptions,\n\u001b[1;32m     78\u001b[0m     VarianceOptions,\n\u001b[1;32m     79\u001b[0m     WeekOptions,\n\u001b[1;32m     80\u001b[0m     \u001b[39m# Functions\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     call_function,\n\u001b[1;32m     82\u001b[0m     function_registry,\n\u001b[1;32m     83\u001b[0m     get_function,\n\u001b[1;32m     84\u001b[0m     list_functions,\n\u001b[1;32m     85\u001b[0m     \u001b[39m# Udf\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     call_tabular_function,\n\u001b[1;32m     87\u001b[0m     register_scalar_function,\n\u001b[1;32m     88\u001b[0m     register_tabular_function,\n\u001b[1;32m     89\u001b[0m     register_aggregate_function,\n\u001b[1;32m     90\u001b[0m     UdfContext,\n\u001b[1;32m     91\u001b[0m     \u001b[39m# Expressions\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     Expression,\n\u001b[1;32m     93\u001b[0m )\n\u001b[1;32m     95\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m namedtuple\n\u001b[1;32m     96\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:404\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import librosa\n",
    "import dagshub\n",
    "import mlflow\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # GPU is available\n",
    "    print(\"GPU is available.\")\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    # GPU is not available\n",
    "    print(\"GPU is not available. PyTorch will use the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dagshub.init(repo_owner=\"stephenjera\", repo_name=\"Genre-Classification\", mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "DURATION = 30  # length of audio files measured in seconds\n",
    "NUM_SEGMENTS = 1\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = Path.cwd().parent / \"data\"\n",
    "genres_dir = data_directory / \"genres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mfcc(\n",
    "    dataset_path: str | Path, #Can input the path or of string format\n",
    "    json_path: str,\n",
    "    samples_per_track: int,\n",
    "    n_mfcc=13,\n",
    "    n_fft=2048,\n",
    "    hop_length=512,\n",
    "    num_segments=5,\n",
    "):\n",
    "    \"\"\"Creates a JSON file of the MFCCs for the dataset\n",
    "    :param\n",
    "    ----------\n",
    "     dataset_path: path to the dataset folder\n",
    "     json_path: name of JSON file to be created\n",
    "     n_mfcc: number of MFCC coefficients to create\n",
    "     n_fft:\n",
    "     hop_length:\n",
    "     num_segments:\n",
    "\n",
    "    \"\"\"\n",
    "    # Create a dictionary to map semantic labels to numerical labels\n",
    "    semantic_to_numeric = {}\n",
    "    # dictionary to store data\n",
    "    data = {\n",
    "        \"mappings\": {},\n",
    "        \"mfcc\": [],\n",
    "        \"labels\": [],\n",
    "    }\n",
    "    num_samples_per_segment = int(samples_per_track / num_segments)\n",
    "    expected_num_mfcc_vectors_per_segment = ceil(\n",
    "        num_samples_per_segment / hop_length\n",
    "    )  # round up always\n",
    "\n",
    "    # Loop through all the data\n",
    "    for i, (dirpath, _, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        # dirpath = current folder path\n",
    "        # dirnames = subfolders in dirpath\n",
    "        # filenames = all files in dirpath\n",
    "\n",
    "        # ensure that we're not at the root level (Audio folder)\n",
    "        if dirpath != str(dataset_path):\n",
    "            # save the semantic label\n",
    "            dirpath_components = dirpath.split(os.sep)\n",
    "            semantic_label = dirpath_components[-1]\n",
    "            # Subtract 1 to skip the root folder\n",
    "            semantic_to_numeric[semantic_label] = i - 1\n",
    "            print(f\"\\nProcessing {semantic_label}\")\n",
    "\n",
    "            # process files\n",
    "            for filename in filenames:\n",
    "                # load audio file\n",
    "                file_path = Path(dirpath, filename)  # os.path.join(dirpath, filename)\n",
    "                try:\n",
    "                    signal, sr = librosa.load(\n",
    "                        file_path  # , sr=SAMPLE_RATE, duration=DURATION\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_path}: {e}\")\n",
    "                    continue\n",
    "                # process segments extracting mfcc and storing data\n",
    "                for s in range(num_segments):\n",
    "                    start_sample = num_samples_per_segment * s\n",
    "                    finish_sample = start_sample + num_samples_per_segment\n",
    "\n",
    "                    mfcc = librosa.feature.mfcc(\n",
    "                        y=signal[start_sample:finish_sample],\n",
    "                        sr=sr,\n",
    "                        n_fft=n_fft,\n",
    "                        n_mfcc=n_mfcc,\n",
    "                        hop_length=hop_length,\n",
    "                    )\n",
    "                    mfcc = mfcc.T\n",
    "\n",
    "                    # store mfcc for segment if it has expected length\n",
    "                    if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n",
    "                        # can't save numpy arrays as json files\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i - 1)\n",
    "                        print(f\"{file_path}, segment:{s+1}\")\n",
    "    data[\"mappings\"] = semantic_to_numeric\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mfcc(genres_dir, \"data.json\", SAMPLES_PER_TRACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "    \"\"\"\n",
    "    Loads training dataset from json file.\n",
    "        :param data_path (str): Path to json file containing data\n",
    "        :return X (ndarray): Inputs\n",
    "        :return y (ndarray): Targets\n",
    "    \"\"\"\n",
    "\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    # convert lists to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    # X = np.array(data[\"spectrogram\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "    mappings = data[\"mappings\"]\n",
    "    return X, y, mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model\n",
    "class LSTMGenreModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super().__init__() # super initialises attributes of parent class\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x): #Forward tells PyTorch how to manipulate the data\n",
    "        # x shape: (batch, seq_len, input_size)\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        # out shape: (batch, seq_len, hidden_size)\n",
    "\n",
    "        # Take the final output and classify\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        # out shape: (batch, num_classes)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Dataset\n",
    "class MFCCDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfccs = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        return mfccs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(data_directory,\"processed\", \"genres_mfccs.json\")\n",
    "X, y, mappings = load_data(path)\n",
    "X = torch.tensor(np.array(X, dtype=np.float32)).clone().detach()\n",
    "y = torch.tensor(y, dtype=torch.long).clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(X, y, test_size, validation_size, shuffle=True, random_state=42):\n",
    "    # create train, validation and test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, shuffle=shuffle, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # create train/validation split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=validation_size\n",
    "    )\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 10  # number of genres\n",
    "input_size = 13  # number of MFCC coefficients\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_val, labels_val = prepare_datasets(X, y, 0.25, 0.2)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = MFCCDataset(X_train, y_train)\n",
    "test_dataset = MFCCDataset(X_test, y_test)\n",
    "val_dataset = MFCCDataset(X_val, labels_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train model\n",
    "model = LSTMGenreModel(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "sample_input = torch.zeros(1, 128, 13).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss() # Used for our loss function\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    for mfccs_test, labels_test in train_loader:\n",
    "        # Move tensors to CUDA\n",
    "        mfccs_test = mfccs_test.to(device)\n",
    "        labels_test = labels_test.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # Zero out the gradients else would be a combination of old gradient\n",
    "        # Forward pass\n",
    "        outputs = model(mfccs_test)\n",
    "\n",
    "        loss = criterion(outputs, labels_test)\n",
    "        loss.backward() # Applies back propogation\n",
    "        optimizer.step() # updating the weights\n",
    "\n",
    "        # Track training metrics\n",
    "        train_loss += loss.item()\n",
    "        # Calculate accuracy for current batch\n",
    "        batch_correct = (outputs.argmax(1) == labels_test).float().sum()\n",
    "        # Convert to python scalar for logging\n",
    "        train_correct += batch_correct.item()\n",
    "    # Average training metrics\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = train_correct / len(train_loader.dataset)  # type: ignore\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "\n",
    "    with torch.no_grad(): # no grad is a context manager, model does not calculate gradient \n",
    "        for mfccs_val, labels_val in val_loader:\n",
    "            # Move tensors to CUDA\n",
    "            mfccs_val = mfccs_val.to(device)\n",
    "            labels_val = labels_val.to(device)\n",
    "            outputs = model(mfccs_val)\n",
    "            val_loss += criterion(outputs, labels_val).item()\n",
    "            val_correct += (outputs.argmax(1) == labels_val).sum().item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_accuracy = val_correct / len(test_loader.dataset)  # type: ignore\n",
    "\n",
    "    # Log metrics to TensorBoard\n",
    "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/Valid\", val_loss, epoch)\n",
    "\n",
    "    writer.add_scalar(\"Accuracy/Train\", train_accuracy, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Valid\", val_accuracy, epoch)\n",
    "\n",
    "    # Log FC layer weights\n",
    "    writer.add_histogram(\"FC Weights\", model.fc.weight)\n",
    "\n",
    "    # Log RNN layer weights\n",
    "    writer.add_histogram(\"RNN Weights\", model.lstm.weight_ih_l0)\n",
    "\n",
    "    writer.add_graph(model, sample_input)\n",
    "\n",
    "model.to(\"cpu\")\n",
    "\n",
    "# Evaluation\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for mfccs_test, labels_test in test_loader:\n",
    "        outputs = model(mfccs_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels_test.size(0)\n",
    "        correct += (predicted == labels_test).sum().item()\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log parameters\n",
    "mlflow.start_run()\n",
    "\n",
    "mlflow.log_metric(\"accuracy\", accuracy)\n",
    "mlflow.log_param(\"SAMPLE_RATE\", SAMPLE_RATE)\n",
    "mlflow.log_param(\"DURATION\", DURATION)\n",
    "mlflow.log_param(\"NUM_SEGMENTS\", NUM_SEGMENTS)\n",
    "mlflow.log_param(\"SAMPLES_PER_TRACK\", SAMPLES_PER_TRACK)\n",
    "mlflow.log_param(\"num_classes\", num_classes)\n",
    "mlflow.log_param(\"input_size\", input_size)\n",
    "mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "mlflow.log_param(\"num_layers\", num_layers)\n",
    "mlflow.log_param(\"batch_size\", batch_size)\n",
    "mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "mlflow.log_param(\n",
    "    \"data_version\",\n",
    "    subprocess.check_output(\n",
    "        [\"git\", \"rev-parse\", \"HEAD\"], universal_newlines=True\n",
    "    ).strip(),\n",
    ")\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "pred_model = LSTMGenreModel(input_size, hidden_size, num_layers, num_classes)\n",
    "pred_model.load_state_dict(torch.load('model.pth'))\n",
    "pred_model.eval()\n",
    "# Assuming that `data` is your new input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_data = torch.tensor(test_loader.dataset.X[0])\n",
    "if len(single_data.shape) < 3:\n",
    "    # Add one dimension for batch with unsqueeze() if your data is 2D (sequence length, features)\n",
    "    single_data = single_data.unsqueeze(0)\n",
    "    #print(single_data.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(single_data)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predicted_genre_name = list(mappings.keys())[list(mappings.values()).index(predicted.item())]\n",
    "    actual_genre_name = list(mappings.keys())[list(mappings.values()).index(test_loader.dataset.y[0])]\n",
    "    print(f\"Predicted class: {predicted_genre_name} {predicted.item()}, Actual: {actual_genre_name} {test_loader.dataset.y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `true_labels` is a list of true labels and `pred_labels` is a list of predicted labels\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mfcc, label in test_loader:\n",
    "        outputs = model(mfcc)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_labels.extend(label.tolist())\n",
    "        pred_labels.extend(predicted.tolist())\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "# Get genre names in the order of label numbers\n",
    "genre_names = [k for k, v in sorted(mappings.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Plot confusion matrix with genre names as labels\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=genre_names,\n",
    "    yticklabels=genre_names,\n",
    "    ax=ax\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "\n",
    "# Rotate y-axis labels\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Log the confusion matrix as an image to TensorBoard\n",
    "writer.add_figure('Confusion Matrix', fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Start TensorBoard within the notebook using magics function\n",
    "%tensorboard --logdir runs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Genre-Classification-Tl9UQQdU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
