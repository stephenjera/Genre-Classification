{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "import pytorch_lightning as pl\n",
    "import mlflow\n",
    "import dagshub\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from pathlib import Path\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.profilers import PyTorchProfiler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "NUM_CLASSES = 10  # number of genres\n",
    "INPUT_SIZE = 13  # number of MFCC coefficients\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 2\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "NUM_WORKERS = 1\n",
    "VALIDATION_SIZE = 0.25\n",
    "TEST_SIZE = 0.2\n",
    "DATASET_PATH = Path.cwd().parent / \"data\" / \"processed\" / \"genres_mfccs.json\"\n",
    "\n",
    "ARTIFACT_PATH = \"genre_classifier\"\n",
    "MODEL_NAME = \"genre-classifier\"\n",
    "\n",
    "CONDA_PATH = Path.cwd().parent / \"environment.yaml\"\n",
    "CODE_PATH = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class MFCCDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfccs = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        return mfccs, label\n",
    "\n",
    "\n",
    "class MFCCDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path,\n",
    "        batch_size,\n",
    "        num_workers,\n",
    "        test_size,\n",
    "        validation_size,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dataset_path = dataset_path\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.test_size = test_size\n",
    "        self.validation_size = validation_size\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data(dataset_path):\n",
    "        \"\"\"\n",
    "        Loads training dataset from json file.\n",
    "            :param data_path (str): Path to json file containing data\n",
    "            :return X (ndarray): Inputs\n",
    "            :return y (ndarray): Targets\n",
    "        \"\"\"\n",
    "        with open(dataset_path, \"r\") as fp:\n",
    "            print(\"Loading Data\")\n",
    "            data = json.load(fp)\n",
    "            # convert lists to numpy arrays\n",
    "            X = np.array(data[\"mfcc\"])\n",
    "            # X = np.array(data[\"spectrogram\"])\n",
    "            y = np.array(data[\"labels\"])\n",
    "            mappings = data[\"mappings\"]\n",
    "            return X, y, mappings\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_datasets(\n",
    "        X, y, test_size, validation_size, shuffle=True, random_state=42\n",
    "    ):\n",
    "        # create train, validation and test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            test_size=test_size,\n",
    "            shuffle=shuffle,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        # create train/validation split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=validation_size\n",
    "        )\n",
    "\n",
    "        return X_train, y_train, X_test, y_test, X_val, y_val\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Load data\n",
    "        self.X, self.y, _ = self.load_data(self.dataset_path)\n",
    "\n",
    "        # Convert to tensors\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.y, dtype=torch.long)\n",
    "\n",
    "        # Create train/val/test split\n",
    "        (\n",
    "            self.X_train,\n",
    "            self.y_train,\n",
    "            self.X_val,\n",
    "            self.y_val,\n",
    "            self.X_test,\n",
    "            self.y_test,\n",
    "        ) = self.prepare_datasets(\n",
    "            self.X,\n",
    "            self.y,\n",
    "            self.test_size,\n",
    "            self.validation_size,\n",
    "        )\n",
    "\n",
    "        # Create dataset objects\n",
    "        self.train_dataset = MFCCDataset(self.X_train, self.y_train)\n",
    "        self.test_dataset = MFCCDataset(self.X_test, self.y_test)\n",
    "        self.val_dataset = MFCCDataset(self.X_val, self.y_val)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "\n",
    "class LSTMGenreModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        num_classes,\n",
    "        learning_rate,\n",
    "        dataset_path: str | Path,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.dataset_path = dataset_path\n",
    "        self.learning_rate = learning_rate\n",
    "        self.accuracy = torchmetrics.Accuracy(\n",
    "            task=\"multiclass\", num_classes=num_classes\n",
    "        )\n",
    "        self.f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "    def _common_step(self, batch):\n",
    "        mfccs, labels = batch\n",
    "        outputs = self(mfccs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        return loss, outputs, labels\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        loss, outputs, labels = self._common_step(batch)\n",
    "        accuracy = self.accuracy(outputs, labels)\n",
    "        f1_score = self.f1_score(outputs, labels)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"train_loss\": loss,\n",
    "                \"train_accuracy\": accuracy,\n",
    "                \"train_f1_score\": f1_score,\n",
    "            },\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return {\"loss\": loss, \"outputs\": outputs, \"labels\": labels}\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        loss, outputs, labels = self._common_step(batch)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    # Test step\n",
    "    def test_step(self, batch):\n",
    "        loss, outputs, labels = self._common_step(batch)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_path, filename=\"checkpoint.ckpt\"):\n",
    "        torch.save(self.state_dict(), os.path.join(checkpoint_path, filename))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMGenreModel(\n",
    "        input_size=INPUT_SIZE,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        dataset_path=DATASET_PATH,\n",
    "    )\n",
    "\n",
    "dm = MFCCDataModule(\n",
    "    dataset_path=DATASET_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    validation_size=VALIDATION_SIZE,\n",
    "    test_size=TEST_SIZE,\n",
    ")\n",
    "\n",
    "# dagshub.init(\n",
    "#     repo_owner=\"stephenjera\",\n",
    "#     repo_name=\"Genre-Classification\",\n",
    "#     mlflow=True,\n",
    "# )\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "# logger = TensorBoardLogger(\"tb_runs\")\n",
    "profiler = PyTorchProfiler(\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler(\"tb_runs/profiler0\"),\n",
    "    schedule=torch.profiler.schedule(\n",
    "        skip_first=10,\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=20,\n",
    "    ),\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    # profiler=profiler,\n",
    "    # logger=logger,\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    log_every_n_steps=25,\n",
    ")\n",
    "trainer.fit(model, dm)\n",
    "# trainer.validate(model, dm)\n",
    "# trainer.test(model, dm)\n",
    "# trainer.save_checkpoint(\"checkpoint.ckpt\")\n",
    "\n",
    "\n",
    "# Create sample input\n",
    "input_tensor = torch.rand(1, 259, 13) \n",
    "# Make predictions\n",
    "predictions = model(input_tensor)\n",
    "# Input tensor\n",
    "input_np = input_tensor.numpy() \n",
    "# Output tensor \n",
    "predictions_np = predictions.detach().numpy()\n",
    "# Infer signature\n",
    "signature = infer_signature(input_np, predictions_np)\n",
    "\n",
    "mlflow.pytorch.log_model(\n",
    "    pytorch_model=model,\n",
    "    artifact_path=MODEL_NAME,\n",
    "    conda_env=str(CONDA_PATH),\n",
    "    # code_paths=[str(CODE_PATH)],\n",
    "    signature=signature\n",
    ")\n",
    "run_id = mlflow.active_run().info.run_id\n",
    "# mlflow.register_model(f\"runs:/{run_id}/{ARTIFACT_PATH}\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, mapings = MFCCDataModule.load_data(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_mfcc = X[:1].tolist()\n",
    "\n",
    "# Make prediction request\n",
    "url = 'http://localhost:1234/invocations'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "data = {\n",
    "  \"instances\": single_mfcc\n",
    "}\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "# Print prediction\n",
    "pprint(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_dict = {v: k for k, v in mapings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = response.json()['predictions']\n",
    "\n",
    "# Convert the predictions to a numpy array\n",
    "predictions_array = np.array(predictions)\n",
    "\n",
    "# Find the index of the maximum value\n",
    "argmax_index = np.argmax(predictions_array)\n",
    "\n",
    "print(f\"prediction:{argmax_index}, {reverse_dict[argmax_index]} Actual {y[0]}, {reverse_dict[y[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genre-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
